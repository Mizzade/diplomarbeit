{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import collections\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Matches of descriptor matching using Mutual Nearest Neighbour Method (NN2W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### SETTINGS\n",
    "#####################\n",
    "root_dir = '/home/mizzade/Workspace/diplom/code'\n",
    "image_dir = os.path.join(root_dir, 'data')\n",
    "data_dir = os.path.join(root_dir, 'outputs')\n",
    "output_dir = '/home/mizzade/Workspace/diplom/outputs/descriptors/nn2way'\n",
    "\n",
    "iname1 = '1.png'\n",
    "iname2 = '2.png'\n",
    "fname1 = '1_10000.csv'\n",
    "fname2 = '2_10000.csv'\n",
    "file_scheme = '_10000.csv'\n",
    "\n",
    "collection_name = 'eisert'\n",
    "collection_path_data = os.path.join(data_dir, collection_name)\n",
    "collection_path_img = os.path.join(image_dir, collection_name)\n",
    "\n",
    "kpts_thresholds = [1000, 5000, 10000]\n",
    "desc_distance_thresholds = [0.7]\n",
    "\n",
    "\n",
    "#####################\n",
    "### FUNCTIONS\n",
    "#####################\n",
    "\n",
    "def normalize_descriptors(desc:np.array) -> np.array:\n",
    "    \"\"\"Creates unit vectors for each descriptor.\"\"\"    \n",
    "    _n = np.linalg.norm(desc, axis=1, ord=2) # Get norms of each vector\n",
    "    _d = desc / _n.reshape(-1, 1)            # Build unit vector\n",
    "    \n",
    "    return _d\n",
    "\n",
    "def nn_match_two_way(desc1, desc2, nn_thresh):\n",
    "    \"\"\"\n",
    "    Performs two-way nearest neighbor matching of two sets of descriptors, such\n",
    "    that the NN match from descriptor A->B must equal the NN match from B->A.\n",
    "\n",
    "    Inputs:\n",
    "      desc1 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      desc2 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      nn_thresh - Optional descriptor distance below which is a good match.\n",
    "\n",
    "    Returns:\n",
    "      matches - Lx3 numpy array, of L matches, where L <= N and each column i is\n",
    "                a match of two descriptors, d_i in image 1 and d_j' in image 2:\n",
    "                [d_i index, d_j' index, match_score]\n",
    "    \"\"\"\n",
    "    # Check if descriptor dimensions match\n",
    "    assert desc1.shape[1] == desc2.shape[1]\n",
    "\n",
    "    # Return zero matches, if one image does not have a keypoint and\n",
    "    # therefore no descriptors.\n",
    "    if desc1.shape[0] == 0 or desc2.shape[0] == 0:\n",
    "        return np.zeros((0, 3))\n",
    "    if nn_thresh < 0.0:\n",
    "        raise ValueError('\\'nn_thresh\\' should be non-negative')\n",
    "\n",
    "    # Compute L2 distance. Easy since vectors are unit normalized.\n",
    "    dmat = np.dot(desc1, desc2.T)\n",
    "    dmat = np.sqrt(2-2*np.clip(dmat, -1, 1))\n",
    "\n",
    "    # Get NN indices and scores.\n",
    "    idx = np.argmin(dmat, axis=1)\n",
    "    scores = dmat[np.arange(dmat.shape[0]), idx]\n",
    "    \n",
    "    # Threshold the NN matches.\n",
    "    keep = scores < nn_thresh\n",
    "   \n",
    "    # Check if nearest neighbor goes both directions and keep those.\n",
    "    idx2 = np.argmin(dmat, axis=0)\n",
    "    keep_bi = np.arange(len(idx)) == idx2[idx]\n",
    "    keep = np.logical_and(keep, keep_bi)\n",
    "    idx = idx[keep]\n",
    "    scores = scores[keep]\n",
    "   \n",
    "    # Get the surviving point indices.\n",
    "    m_idx1 = np.arange(desc1.shape[0])[keep]\n",
    "    m_idx2 = idx\n",
    "    \n",
    "    # Populate the final Nx3 match data structure.\n",
    "    matches = np.zeros((int(keep.sum()), 3))\n",
    "    matches[:, 0] = m_idx1\n",
    "    matches[:, 1] = m_idx2\n",
    "    matches[:, 2] = scores\n",
    "    return matches\n",
    "\n",
    "def save_figure(\n",
    "  path_output:str,\n",
    "  fig_name:str, \n",
    "  figure: mpl.figure.Figure,\n",
    "  dpi:int=1200,\n",
    "  tight_layout:bool=False) -> None:\n",
    "\n",
    "    if not os.path.exists(path_output):\n",
    "        os.makedirs(path_output, exist_ok=True)\n",
    "\n",
    "    f_out = os.path.join(path_output, fig_name)\n",
    "  \n",
    "    if tight_layout:\n",
    "        figure.savefig(f_out, bbox_inches='tight', pad_inches=0, dpi=dpi)\n",
    "    else:\n",
    "        figure.savefig(f_out, dpi=dpi)\n",
    "        \n",
    "#####################\n",
    "### MAIN\n",
    "#####################\n",
    "\n",
    "# NOTE: To avoid memory errors, handle number of descriptors, detectors,\n",
    "# keypoint threshold etc with car.\n",
    "\n",
    "set_names = sorted([x for x in os.listdir(collection_path_img) if os.path.isdir(os.path.join(collection_path_img, x))])\n",
    "\n",
    "\n",
    "for set_name in tqdm(set_names):\n",
    "    \n",
    "    # 1. Open folder of set\n",
    "    set_path_2_desc = os.path.join(collection_path_data, set_name, 'descriptors')\n",
    "    descriptor_names = sorted([x for x in os.listdir(set_path_2_desc) \\\n",
    "                               if os.path.isdir(os.path.join(set_path_2_desc, x))])\n",
    "    \n",
    "    # 2. Open the images\n",
    "    imgs_path  = os.path.join(image_dir, collection_name, set_name)\n",
    "    img1 = mpimg.imread(os.path.join(imgs_path, iname1))\n",
    "    img2 = mpimg.imread(os.path.join(imgs_path, iname2))\n",
    "     \n",
    "    # Offset for keypoints in image 2, when we stack images\n",
    "    # next to each other.\n",
    "    offsets = np.array([img1.shape[1], 0])\n",
    "    \n",
    "    # Scalefactor for tcovdet\n",
    "    _h, _w = img1.shape[:2]\n",
    "    tcovdet_sf = 1.0\n",
    "    if (_h * _w) > 1024:\n",
    "        tcovdet_sf = 1. / (1024 * 768 / float(_h * _w))**(0.5)\n",
    "        #tcovdet_sf = (_h * _w) / 1024.\n",
    "    \n",
    "    # Stack images next to each other.\n",
    "    img = np.hstack([img1, img2])\n",
    "    \n",
    "    \n",
    "    # Remove not needed single images\n",
    "    del img1, img2, _h, _w\n",
    "    gc.collect()\n",
    "    \n",
    "    for descriptor_name in descriptor_names:\n",
    "        print(descriptor_name)\n",
    "        set_path_2_dets = os.path.join(set_path_2_desc, descriptor_name)\n",
    "        \n",
    "        detector_names = sorted([x for x in os.listdir(set_path_2_dets) \\\n",
    "                                 if os.path.isdir(os.path.join(set_path_2_dets, x))])\n",
    "        \n",
    "        for detector_name in detector_names:\n",
    "            print('\\t', detector_name)\n",
    "            set_path_2_files = os.path.join(set_path_2_dets, detector_name)\n",
    "            file_names = sorted([x for x in os.listdir(set_path_2_files) if file_scheme in x])\n",
    "            \n",
    "            # 3. Open detector keypoints.\n",
    "            kpts_path = os.path.join(collection_path_data, set_name, 'keypoints', detector_name)\n",
    "            kpts1 = pd.read_csv(os.path.join(kpts_path, fname1), sep=',', comment='#', header=None, usecols=[0, 1]).values\n",
    "            kpts2 = pd.read_csv(os.path.join(kpts_path, fname2), sep=',', comment='#', header=None, usecols=[0, 1]).values\n",
    "            \n",
    "            # 3.1 If detector is tcovdet, we have to scale keypoints.\n",
    "            if detector_name == 'tcovdet':\n",
    "                kpts1 = kpts1 * tcovdet_sf\n",
    "                kpts2 = kpts2 * tcovdet_sf\n",
    "\n",
    "            # 4. Open corresponding descriptors\n",
    "            desc_path = os.path.join(collection_path_data, set_name, 'descriptors', descriptor_name, detector_name)\n",
    "            desc1 = pd.read_csv(os.path.join(desc_path, fname1), sep=',', comment='#', header=None).values\n",
    "            desc2 = pd.read_csv(os.path.join(desc_path, fname2), sep=',', comment='#', header=None).values\n",
    "            desc1 = normalize_descriptors(desc1)\n",
    "            desc2 = normalize_descriptors(desc2)\n",
    "            \n",
    "            for kpts_thresh in kpts_thresholds:\n",
    "                # 4. Get the subset of descriptors and detectors\n",
    "                # Make a copy, otherwise you overwrite the slices of \n",
    "                # the original.\n",
    "                d1 = desc1[:kpts_thresh].copy()\n",
    "                d2 = desc2[:kpts_thresh].copy()\n",
    "                k1 = kpts1[:kpts_thresh].copy()\n",
    "                k2 = kpts2[:kpts_thresh].copy()\n",
    "                \n",
    "                for desc_dist in desc_distance_thresholds:\n",
    "                    # 5. Make Nearest Neighbour Two Way Matching for each desc_dist\n",
    "                    # Column1 contains match indices of d1.\n",
    "                    # Column2 contains match indices of d2.\n",
    "                    # Column3 contains distance of descriptors.\n",
    "                    res = nn_match_two_way(d1, d2, desc_dist)\n",
    "    \n",
    "                    # Apply offsets to keypoints in image 2\n",
    "                    k2 += offsets\n",
    "                        \n",
    "                    idx1 = res[:, 0].astype(np.int)\n",
    "                    idx2 = res[:, 1].astype(np.int)\n",
    "                    \n",
    "                    hits1 = (k1.copy())[idx1]\n",
    "                    misses1 = np.delete(k1, idx1, 0)\n",
    "                    hits2 = (k2.copy())[idx2]\n",
    "                    misses2 = np.delete(k2, idx2, 0)\n",
    "                    \n",
    "                    hits = np.vstack([hits1, hits2])\n",
    "                    misses = np.vstack([misses1, misses2])\n",
    "\n",
    "                    # 5. Draw and save the image.\n",
    "                    fig, ax = plt.subplots(1, 1)\n",
    "                    # Draw image\n",
    "                    ax.imshow(img)\n",
    "\n",
    "                    # Draw misses (no matching keypoints)\n",
    "                    ax.scatter(misses[:, 0], misses[:, 1], color='blue', marker='o', s=0.5, alpha=0.5)\n",
    "\n",
    "                    # Draw lines of matches from image1 to image2\n",
    "                    for idx, _ in enumerate(res):\n",
    "                        pos = np.vstack([hits1[idx], hits2[idx]])\n",
    "                        ax.plot(pos[:, 0], pos[:, 1], color='lawngreen', alpha=1, linewidth=0.5)\n",
    "\n",
    "                    # Draw hits (matching keypoints)\n",
    "                    ax.scatter(hits[:, 0], hits[:, 1], color='r', marker='o', s=0.5)\n",
    "                    \n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    \n",
    "                    fig_name = '{}_{}__{}_{}__{}_{}.png' \\\n",
    "                        .format(descriptor_name, detector_name, collection_name, set_name, kpts_thresh, desc_dist)\n",
    "                    \n",
    "                    save_figure(output_dir, fig_name, fig, tight_layout=True)\n",
    "                    plt.close(fig)\n",
    "                    \n",
    "                    # Free some memory\n",
    "                    del k1, k2, d1, d2, hits1, hits2, misses1, misses2, res, pos\n",
    "                    gc.collect()\n",
    "                    \n",
    "            # Free some memory\n",
    "            del kpts1, kpts2, desc1, desc2\n",
    "            gc.collect()\n",
    "            \n",
    "    # Free even more memory\n",
    "    del img\n",
    "    gc.collect()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
