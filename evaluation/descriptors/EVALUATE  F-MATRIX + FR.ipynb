{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import collections\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get statistics for Fundamental Matrix Estimation using FLANN and Ratio Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 1/13 [00:04<00:57,  4.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 2/13 [00:09<00:51,  4.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 3/13 [00:16<00:55,  5.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 4/13 [00:24<00:54,  6.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 5/13 [00:31<00:51,  6.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 6/13 [00:38<00:45,  6.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████▍    | 7/13 [00:44<00:38,  6.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 8/13 [00:50<00:31,  6.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████▉   | 9/13 [00:54<00:22,  5.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|███████▋  | 10/13 [01:01<00:17,  5.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▍ | 11/13 [01:04<00:10,  5.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 12/13 [01:07<00:04,  4.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 13/13 [01:09<00:00,  3.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### FUNCTIONS\n",
    "#####################\n",
    "\n",
    "def normalize_descriptors(desc:np.array) -> np.array:\n",
    "    \"\"\"Creates unit vectors for each descriptor.\"\"\"    \n",
    "    _n = np.linalg.norm(desc, axis=1, ord=2) # Get norms of each vector\n",
    "    _d = desc / _n.reshape(-1, 1)            # Build unit vector\n",
    "    \n",
    "    return _d\n",
    "\n",
    "def compute_distances_kpts_to_epilines(points_i, points_j, F:np.array) -> np.array:\n",
    "    \"\"\"Given two sets of matching points [Nx2] returns the an array of absolute\n",
    "    distances [Nx2], where as the first column contains the distances of the \n",
    "    first points to the  epipolar lines in the first image and the second image\n",
    "    vise versa.\"\"\"\n",
    "    assert points_i.shape[1] == 2\n",
    "    assert points_j.shape[1] == 2\n",
    "    assert points_i.shape == points_j.shape\n",
    "    \n",
    "    if F is None:\n",
    "        return (np.zeros((points_i.shape[0], 2)) + np.inf)\n",
    "\n",
    "    # Epipolar lines in image I of the points in image J\n",
    "    lines_i = cv2.computeCorrespondEpilines(points_j.reshape(-1, 1, 2), 2, F).reshape(-1, 3)\n",
    "\n",
    "    # Epipolar lines in image J of the points in image I\n",
    "    lines_j = cv2.computeCorrespondEpilines(points_i.reshape(-1, 1, 2), 1, F).reshape(-1, 3)\n",
    "\n",
    "    dist = []\n",
    "    for k in range(points_i.shape[0]):\n",
    "        # Params for image i\n",
    "        xi, yi = points_i[k]\n",
    "        ai, bi, ci = lines_i[k]\n",
    "\n",
    "        # Params for image j\n",
    "        xj, yj = points_j[k]\n",
    "        aj, bj, cj = lines_j[k]\n",
    "\n",
    "        di = np.abs(ai*xi + bi*yi + ci) / np.sqrt(ai*ai + bi*bi)\n",
    "        dj = np.abs(aj*xj + bj*yj + cj) / np.sqrt(aj*aj + bj*bj)\n",
    "\n",
    "        dist.append((di, dj))\n",
    "\n",
    "    dist = np.array(dist)\n",
    "    return dist\n",
    "\n",
    "def save_stats(\n",
    "    path_output:str,\n",
    "    fout_name,\n",
    "    collection_name:str,\n",
    "    df:pd.DataFrame,\n",
    "    fast_eval:bool=False) -> None:\n",
    "    \n",
    "    if not os.path.exists(path_output):\n",
    "        os.makedirs(path_output, exist_ok=True)\n",
    "\n",
    "    df.to_csv(os.path.join(path_output, fout_name), \n",
    "              index=False, \n",
    "              encoding='utf-8')\n",
    "\n",
    "#####################\n",
    "### DATAFRAME\n",
    "#####################\n",
    "\"\"\"\n",
    "collection_name:str             Name of the collection\n",
    "set_name:str                    Name of the set\n",
    "kpts_threshold:int              Number of used features\n",
    "descriptor_name:str             Name of descriptor\n",
    "detector_name:str               Name of detector\n",
    "matching_method:str             Name of matching method\n",
    "desc_distance_threshold:float   Maximal distance of two descriptor to match for nn2w method\n",
    "\n",
    "max_num_matches:int             Maximal number of possible matches\n",
    "num_matches:int                 Actual number of matches\n",
    "matchability:float              Ratio of num_matches and max_num_matches\n",
    "accuracy:float                  Mean of 1 - (score of match / desc_distance_threshold)\n",
    "mse_matching:float              Mean squared error of matched desriptors.\n",
    "\n",
    "max_num_inliers:int             Maximal number of inliers for F-matrix\n",
    "num_inliers:int                 Actual number of inliers for F-matrix\n",
    "inlier_ratio:float              Ratio between num_inliers and max_num_inliers\n",
    "avg_distance:float              Mean distance between keypoints and corresponding epipolar line\n",
    "mse_estimation:float            Mean squared error\n",
    "\"\"\"\n",
    "\n",
    "column_names = ['collection_name', 'set_name', 'kpts_threshold',\n",
    "                'descriptor_name', 'detector_name', 'matching_method',\n",
    "                'desc_distance_threshold', 'max_num_matches',\n",
    "                'num_matches', 'matchability', 'accuracy',\n",
    "                'mse_matching', 'max_num_inliers', 'num_inliers', \n",
    "                'inlier_ratio', 'avg_distance','mse_estimation']\n",
    "\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "#####################\n",
    "### SETTINGS\n",
    "#####################\n",
    "\n",
    "root_dir = '/home/mizzade/Workspace/diplom/code'\n",
    "image_dir = os.path.join(root_dir, 'data')\n",
    "data_dir = os.path.join(root_dir, 'outputs')\n",
    "output_dir = '/home/mizzade/Workspace/diplom/outputs/eval_matching_pipeline'\n",
    "\n",
    "iname1 = '1.png'\n",
    "iname2 = '2.png'\n",
    "fname1 = '1_10000.csv'\n",
    "fname2 = '2_10000.csv'\n",
    "file_scheme = '_10000.csv'\n",
    "matching_method = 'flann_ratio'\n",
    "\n",
    "collection_name = 'eisert'\n",
    "collection_path_data = os.path.join(data_dir, collection_name)\n",
    "collection_path_img = os.path.join(image_dir, collection_name)\n",
    "\n",
    "kpts_thresholds = [1000, 5000, 10000]\n",
    "desc_distance_thresholds = [0.7]\n",
    "\n",
    "fout_name = 'descriptor_matching_{}_fr_fmatrix'.format(collection_name)\n",
    "    \n",
    "#####################\n",
    "### MAIN\n",
    "#####################\n",
    "# NOTE: To avoid memory errors, handle number of descriptors, detecotrs,\n",
    "# keypoint threshold etc with care.\n",
    "\n",
    "\n",
    "set_names = sorted([x for x in os.listdir(collection_path_img) \\\n",
    "                    if os.path.isdir(os.path.join(collection_path_img, x))])\n",
    "\n",
    "fast_eval = True\n",
    "verbose = False\n",
    "\n",
    "fout_name = fout_name + '_fast.csv' if fast_eval else fout_name + '.csv'\n",
    "\n",
    "# Create descriptor matcher using L2-Norms.\n",
    "matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "\n",
    "for set_name in tqdm(set_names):\n",
    "    if verbose:\n",
    "        print(set_name)\n",
    "    \n",
    "    # 1. Open folder of set\n",
    "    set_path_2_desc = os.path.join(collection_path_data, set_name, 'descriptors')\n",
    "    desc_names = sorted([x for x in os.listdir(set_path_2_desc) \\\n",
    "                               if os.path.isdir(os.path.join(set_path_2_desc, x))])\n",
    "\n",
    "    descriptor_names = desc_names[:2] if fast_eval else desc_names\n",
    "    for descriptor_name in descriptor_names:\n",
    "        if verbose:\n",
    "            print(descriptor_name)\n",
    "        \n",
    "        set_path_2_dets = os.path.join(set_path_2_desc, descriptor_name)\n",
    "        \n",
    "        det_names = sorted([x for x in os.listdir(set_path_2_dets) \\\n",
    "                                 if os.path.isdir(os.path.join(set_path_2_dets, x))])\n",
    "        \n",
    "        detector_names = det_names[:2] if fast_eval else det_names\n",
    "        for detector_name in detector_names:\n",
    "            if verbose:\n",
    "                print('\\t', detector_name)\n",
    "            \n",
    "            set_path_2_files = os.path.join(set_path_2_dets, detector_name)\n",
    "            file_names = sorted([x for x in os.listdir(set_path_2_files) if file_scheme in x])\n",
    "            \n",
    "            # 2. Open detector keypoints.\n",
    "            kpts_path = os.path.join(collection_path_data, set_name, 'keypoints', detector_name)\n",
    "            kpts1 = pd.read_csv(os.path.join(kpts_path, fname1), sep=',', comment='#', header=None, usecols=[0, 1]).values\n",
    "            kpts2 = pd.read_csv(os.path.join(kpts_path, fname2), sep=',', comment='#', header=None, usecols=[0, 1]).values\n",
    "\n",
    "            # 3. Open corresponding descriptors\n",
    "            desc_path = os.path.join(collection_path_data, set_name, 'descriptors', descriptor_name, detector_name)\n",
    "            desc1 = pd.read_csv(os.path.join(desc_path, fname1), sep=',', comment='#', header=None).values.astype(np.float32)\n",
    "            desc2 = pd.read_csv(os.path.join(desc_path, fname2), sep=',', comment='#', header=None).values.astype(np.float32)\n",
    "            desc1 = normalize_descriptors(desc1)\n",
    "            desc2 = normalize_descriptors(desc2)\n",
    "            \n",
    "            kpts_thresholds = kpts_thresholds[:1] if fast_eval else kpts_thresholds\n",
    "            for kpts_thresh in kpts_thresholds:\n",
    "                # 4. Get the subset of descriptors and detectors\n",
    "                # Make a copy, otherwise you overwrite the slices of \n",
    "                # the original.\n",
    "                d1 = desc1[:kpts_thresh].copy()\n",
    "                d2 = desc2[:kpts_thresh].copy()\n",
    "                k1 = kpts1[:kpts_thresh].copy()\n",
    "                k2 = kpts2[:kpts_thresh].copy()\n",
    "                \n",
    "                max_num_matches = np.min([len(d1), len(d2)])\n",
    "                \n",
    "                for desc_dist in desc_distance_thresholds:\n",
    "                    # Find best 2 matches for each descriptor.\n",
    "                    knn_matches = matcher.knnMatch(d1, d2, 2)\n",
    "                    \n",
    "                    # Filter each matching pair (first, second) using the Lowe's ratio test\n",
    "                    # desc_dist is here the ratio threshold (0.7)\n",
    "                    # Create Nx3 array for the matches containing\n",
    "                    # - the id of the descriptor in d1\n",
    "                    # - the id of the descriptor in d2\n",
    "                    # - the distance between those two\n",
    "                    res = []\n",
    "                    for first_match, second_match in knn_matches:\n",
    "                        if first_match.distance < desc_dist * second_match.distance:\n",
    "                            res.append((first_match.queryIdx, first_match.trainIdx, first_match.distance))\n",
    "                            \n",
    "                    res = np.array(res).reshape(-1, 3)\n",
    "                    \n",
    "                    num_matches = len(res)\n",
    "                    \n",
    "                    matchability = 0 \\\n",
    "                        if max_num_matches == 0 \\\n",
    "                        else num_matches / max_num_matches\n",
    "                    \n",
    "                    accuracy = 0 \\\n",
    "                        if num_matches == 0 \\\n",
    "                        else 1.0 - np.mean(res[:, 2] / desc_dist)\n",
    "                    \n",
    "                    mse_matching = 0 \\\n",
    "                        if num_matches == 0 \\\n",
    "                        else np.mean(np.linalg.norm(res[:, 2]))\n",
    "                    \n",
    "                    max_num_inliers = len(res)\n",
    "                    \n",
    "                    # Indices of kpts1 and kpts2 matches\n",
    "                    idx1 = res[:, 0].astype(np.int)\n",
    "                    idx2 = res[:, 1].astype(np.int)\n",
    "                  \n",
    "                    # Get matching keypoints. Float32 for using cv2 functions.\n",
    "                    hits1 = (k1.copy()[idx1]).astype(np.float32)\n",
    "                    hits2 = (k2.copy()[idx2]).astype(np.float32)\n",
    "                    \n",
    "                    # ransacReprojThreshold: Maximal distance in pixels from point to epipolar line\n",
    "                    # to be condiered inlier.\n",
    "                    # confidence: Confidence value that fundamental matrix is correct.\n",
    "                    F, mask = cv2.findFundamentalMat(\n",
    "                        hits1, \n",
    "                        hits2, \n",
    "                        method=cv2.FM_RANSAC,\n",
    "                        ransacReprojThreshold=3,\n",
    "                        confidence=.99)\n",
    "                    \n",
    "                    if  mask is not None:\n",
    "                        num_inliers = 0 if mask is None else np.sum(mask)\n",
    "                        inlier_ratio = 0 if len(res) == 0 else np.sum(mask) / len(res)\n",
    "                        \n",
    "                        mask = mask.ravel()\n",
    "                        hits1 = hits1[mask==1]\n",
    "                        hits2 = hits2[mask==1]\n",
    "\n",
    "                        # Absolute distances of points to corresponding epipoloar line\n",
    "                        # Column1: distances of points in image1 to epilines\n",
    "                        # Column2: distances of points in image2 to epilines\n",
    "                        #d_errors = compute_distances_kpts_to_epilines(hits1, hits2, F)\n",
    "                        d_errors = compute_distances_kpts_to_epilines(hits1, hits2, F)\n",
    "                        d_errors = d_errors.reshape(-1, 1)\n",
    "                        mean_dist = np.mean(d_errors)\n",
    "                        mse_estimation = 0 \\\n",
    "                            if len(d_errors) == 0 \\\n",
    "                            else np.linalg.norm(d_errors) / len(d_errors)\n",
    "\n",
    "                    else:\n",
    "                        num_inliers = 0\n",
    "                        inlier_ratio = 0\n",
    "                        mean_dist = np.nan\n",
    "                        mse_estimation = np.nan\n",
    "                        \n",
    "                    # Add to dataframe\n",
    "                    df = df.append({\n",
    "                        'collection_name': collection_name, \n",
    "                        'set_name': set_name, \n",
    "                        'kpts_threshold': kpts_thresh,\n",
    "                        'descriptor_name': descriptor_name, \n",
    "                        'detector_name': detector_name, \n",
    "                        'matching_method': matching_method,\n",
    "                        'desc_distance_threshold': desc_dist,\n",
    "                        'max_num_matches': max_num_matches,\n",
    "                        'num_matches': num_matches,\n",
    "                        'matchability': matchability,\n",
    "                        'accuracy': accuracy,\n",
    "                        'mse_matching': mse_matching,\n",
    "                        'max_num_inliers': max_num_inliers,\n",
    "                        'num_inliers': num_inliers,\n",
    "                        'inlier_ratio': inlier_ratio,\n",
    "                        'avg_distance': mean_dist,\n",
    "                        'mse_estimation': mse_estimation\n",
    "                    }, ignore_index=True)\n",
    "                    \n",
    "                    \n",
    "                    # Free memory\n",
    "                    del knn_matches\n",
    "                    del idx1, idx2, F, mask, num_inliers, inlier_ratio, mean_dist, mse_estimation, hits1, hits2\n",
    "                    del num_matches, matchability, accuracy, mse_matching\n",
    "                    gc.collect()\n",
    "                \n",
    "                # Free memory\n",
    "                del d1, d2, k1, k2, max_num_matches\n",
    "                gc.collect()\n",
    "            \n",
    "            # Free memory\n",
    "            del kpts1, kpts2, desc1, desc2\n",
    "            gc.collect()\n",
    "\n",
    "save_stats(\n",
    "    output_dir,\n",
    "    fout_name,\n",
    "    collection_name,\n",
    "    df,\n",
    "    fast_eval=fast_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
