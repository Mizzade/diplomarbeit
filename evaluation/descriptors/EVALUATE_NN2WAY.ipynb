{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import collections\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get statistics of descriptor matching using Mutual Nearest Neighbour Matching (NN2W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate doap with lift\n",
      "Evaluate lift with lift\n",
      "Evaluate sift with lift\n",
      "Evaluate superpoint with superpoint\n",
      "Evaluate tfeat with lift\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.86s/it]\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### SETTINGS\n",
    "#####################\n",
    "root_dir = '/home/mizzade/Workspace/diplom/code'\n",
    "\n",
    "image_dir = os.path.join(root_dir, 'data')\n",
    "data_dir = os.path.join(root_dir, 'outputs')\n",
    "output_dir = '/home/mizzade/Workspace/diplom/outputs/descriptors'\n",
    "\n",
    "\n",
    "collection_name = 'eisert'\n",
    "collection_path_data = os.path.join(data_dir, collection_name)\n",
    "collection_path_img = os.path.join(image_dir, collection_name)\n",
    "\n",
    "\n",
    "set_names = sorted([x for x in os.listdir(collection_path_img) if os.path.isdir(os.path.join(collection_path_img, x))])\n",
    "file_scheme = '_10000.csv'\n",
    "\n",
    "\n",
    "kpts_thresholds = [1000, 5000, 10000]\n",
    "ratio_threshold = 0.7\n",
    "desc_distance_threshold = np.sqrt(2) # nn2w, maximal distance for two descriptors to be a match.\n",
    "desc_distance_thresholds = [desc_distance_threshold]\n",
    "\n",
    "#####################\n",
    "### FUNCTIONS\n",
    "#####################\n",
    "def normalize_descriptors(desc:np.array) -> np.array:\n",
    "    \"\"\"Creates unit vectors for each descriptor.\"\"\"    \n",
    "    _n = np.linalg.norm(desc, axis=1, ord=2) # Get norms of each vector\n",
    "    _d = desc / _n.reshape(-1, 1)            # Build unit vector\n",
    "    \n",
    "    return _d\n",
    "\n",
    "def nn_match_two_way(desc1, desc2, nn_thresh):\n",
    "    \"\"\"\n",
    "    Performs two-way nearest neighbor matching of two sets of descriptors, such\n",
    "    that the NN match from descriptor A->B must equal the NN match from B->A.\n",
    "\n",
    "    Inputs:\n",
    "      desc1 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      desc2 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      nn_thresh - Optional descriptor distance below which is a good match.\n",
    "\n",
    "    Returns:\n",
    "      matches - Lx3 numpy array, of L matches, where L <= N and each column i is\n",
    "                a match of two descriptors, d_i in image 1 and d_j' in image 2:\n",
    "                [d_i index, d_j' index, match_score]\n",
    "    \"\"\"\n",
    "    # Check if descriptor dimensions match\n",
    "    assert desc1.shape[1] == desc2.shape[1]\n",
    "\n",
    "    # Return zero matches, if one image does not have a keypoint and\n",
    "    # therefore no descriptors.\n",
    "    if desc1.shape[0] == 0 or desc2.shape[0] == 0:\n",
    "        return np.zeros((0, 3))\n",
    "    if nn_thresh < 0.0:\n",
    "        raise ValueError('\\'nn_thresh\\' should be non-negative')\n",
    "\n",
    "    # Compute L2 distance. Easy since vectors are unit normalized.\n",
    "    dmat = np.dot(desc1, desc2.T)\n",
    "    dmat = np.sqrt(2-2*np.clip(dmat, -1, 1))\n",
    "\n",
    "    # Get NN indices and scores.\n",
    "    idx = np.argmin(dmat, axis=1)\n",
    "    scores = dmat[np.arange(dmat.shape[0]), idx]\n",
    "    \n",
    "    # Threshold the NN matches.\n",
    "    keep = scores < nn_thresh\n",
    "    # Check if nearest neighbor goes both directions and keep those.\n",
    "    idx2 = np.argmin(dmat, axis=0)\n",
    "    keep_bi = np.arange(len(idx)) == idx2[idx]\n",
    "    keep = np.logical_and(keep, keep_bi)\n",
    "    idx = idx[keep]\n",
    "    scores = scores[keep]\n",
    "    # Get the surviving point indices.\n",
    "    m_idx1 = np.arange(desc1.shape[0])[keep]\n",
    "    m_idx2 = idx\n",
    "    # Populate the final Nx3 match data structure.\n",
    "    matches = np.zeros((int(keep.sum()), 3))\n",
    "    matches[:, 0] = m_idx1\n",
    "    matches[:, 1] = m_idx2\n",
    "    matches[:, 2] = scores\n",
    "    return matches\n",
    "\n",
    "def save_stats(\n",
    "    path_output:str,\n",
    "    collection_name:str,\n",
    "    df:pd.DataFrame,\n",
    "    fast_eval:bool=False) -> None:\n",
    "\n",
    "    fout_name = 'descriptor_matching_{}_nn2w.csv'.format(collection_name)\n",
    "    if fast_eval:\n",
    "        fout_name = 'descriptor_matching_{}_nn2w_fast_eval.csv'.format(collection_name)\n",
    "        \n",
    "    if not os.path.exists(path_output):\n",
    "        os.makedirs(path_output, exist_ok=True)\n",
    "\n",
    "    df.to_csv(os.path.join(path_output, fout_name), \n",
    "              index=False, \n",
    "              encoding='utf-8')\n",
    "    \n",
    "#####################\n",
    "### MAIN\n",
    "#####################\n",
    "\"\"\"\n",
    "collection_name:str      Name of the collection\n",
    "set_name:str             Name of the set in collection\n",
    "kpts_threshold:float     Number of used features\n",
    "descriptor_name:str      Name of descriptor\n",
    "detector_name:str        Name of detector\n",
    "matching_method:str      Name of matching method\n",
    "desc_distance_threshold  Maximal distance of two descriptor to match for nn2w-method\n",
    "max_num_matches:int      Maximal number of possible matches\n",
    "num_matches:int          Actual number of matches\n",
    "matchability:float       Ratio of num_matches and max_num_matches\n",
    "accuracy:float           Mean of 1 - (score of match / desc_distance_threshold)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "column_names = ['collection_name', 'set_name', 'kpts_threshold',\n",
    "               'descriptor_name', 'detector_name', 'matching_method',\n",
    "                'desc_distance_threshold','max_num_matches', \n",
    "                'num_matches', 'matchability', 'accuracy']\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# Target: Iterate over all sets and evaluate all descriptor/detector combinations available.\n",
    "fast_eval = True\n",
    "set_names = [set_names[0]] if fast_eval else set_names\n",
    "kpts_thresholds = [kpts_thresholds[0]] if fast_eval else kpts_thresholds\n",
    "\n",
    "# desc_distance_thresholds = np.linspace(0.1, 1, 10)\n",
    "desc_distance_thresholds = [0.7] # empirisch ermittelt\n",
    "\n",
    "for set_name in tqdm(set_names):\n",
    "    # 1. Open folder of set\n",
    "    set_path_2_desc = os.path.join(collection_path_data, set_name, 'descriptors')\n",
    "    descriptor_names = sorted([x for x in os.listdir(set_path_2_desc) \\\n",
    "                               if os.path.isdir(os.path.join(set_path_2_desc, x))])\n",
    "    \n",
    "    for descriptor_name in descriptor_names:\n",
    "        set_path_2_dets = os.path.join(set_path_2_desc, descriptor_name)\n",
    "        \n",
    "        detector_names = sorted([x for x in os.listdir(set_path_2_dets) \\\n",
    "                                 if os.path.isdir(os.path.join(set_path_2_dets, x))])\n",
    "        \n",
    "        detector_names = [detector_names[0]] if fast_eval else detector_names\n",
    "        for detector_name in detector_names:\n",
    "            #print('Evaluate {} with {}'.format(descriptor_name, detector_name))\n",
    "            set_path_2_files = os.path.join(set_path_2_dets, detector_name)\n",
    "            file_names = sorted([x for x in os.listdir(set_path_2_files) if file_scheme in x])\n",
    "            \n",
    "            # Load descriptors\n",
    "            desc1 = pd.read_csv(os.path.join(set_path_2_files, file_names[0]), sep=',', comment='#', header=None).values\n",
    "            desc2 = pd.read_csv(os.path.join(set_path_2_files, file_names[1]), sep=',', comment='#', header=None).values\n",
    "            \n",
    "            # Normalize descriptors\n",
    "            desc1 = normalize_descriptors(desc1)\n",
    "            desc2 = normalize_descriptors(desc2)\n",
    "            \n",
    "            for kpts_thresh in kpts_thresholds:\n",
    "                # Get the first N descriptors (from the best first N detectors)\n",
    "                d1 = desc1[:kpts_thresh]\n",
    "                d2 = desc2[:kpts_thresh]\n",
    "                \n",
    "                max_num_matches = np.min([len(d1), len(d2)])\n",
    "                \n",
    "                for desc_dist_thresh in desc_distance_thresholds:\n",
    "                    res_nn2w = nn_match_two_way(d1, d2, desc_dist_thresh)\n",
    "                    \n",
    "                    num_matches = len(res_nn2w)\n",
    "                    matchability = 0 if max_num_matches == 0 else num_matches / max_num_matches\n",
    "\n",
    "                    accuracy = 0 if num_matches == 0 else 1.0 - np.mean(res_nn2w[:, 2] / desc_distance_threshold)\n",
    "\n",
    "                    df = df.append({\n",
    "                        'collection_name': collection_name, \n",
    "                        'set_name': set_name, \n",
    "                        'kpts_threshold': kpts_thresh,\n",
    "                        'descriptor_name': descriptor_name, \n",
    "                        'detector_name': detector_name, \n",
    "                        'matching_method': 'nn2w',\n",
    "                        'desc_distance_threshold': desc_dist_thresh,\n",
    "                        'max_num_matches': max_num_matches, \n",
    "                        'num_matches': num_matches, \n",
    "                        'matchability': matchability, \n",
    "                        'accuracy': accuracy\n",
    "                    }, ignore_index=True)\n",
    "\n",
    "save_stats(\n",
    "        output_dir, \n",
    "        collection_name, \n",
    "        df,\n",
    "        fast_eval=fast_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
