{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import collections\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get statistics for Fundamental Matrix Estimation using Mutal Nearest Neighbour Matching (NN2W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "### FUNCTIONS\n",
    "#####################\n",
    "\n",
    "def normalize_descriptors(desc:np.array) -> np.array:\n",
    "    \"\"\"Creates unit vectors for each descriptor.\"\"\"    \n",
    "    _n = np.linalg.norm(desc, axis=1, ord=2) # Get norms of each vector\n",
    "    _d = desc / _n.reshape(-1, 1)            # Build unit vector\n",
    "    \n",
    "    return _d\n",
    "\n",
    "def nn_match_two_way(desc1, desc2, nn_thresh):\n",
    "    \"\"\"\n",
    "    Performs two-way nearest neighbor matching of two sets of descriptors, such\n",
    "    that the NN match from descriptor A->B must equal the NN match from B->A.\n",
    "\n",
    "    Inputs:\n",
    "      desc1 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      desc2 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      nn_thresh - Optional descriptor distance below which is a good match.\n",
    "\n",
    "    Returns:\n",
    "      matches - Lx3 numpy array, of L matches, where L <= N and each column i is\n",
    "                a match of two descriptors, d_i in image 1 and d_j' in image 2:\n",
    "                [d_i index, d_j' index, match_score]\n",
    "    \"\"\"\n",
    "    # Check if descriptor dimensions match\n",
    "    assert desc1.shape[1] == desc2.shape[1]\n",
    "\n",
    "    # Return zero matches, if one image does not have a keypoint and\n",
    "    # therefore no descriptors.\n",
    "    if desc1.shape[0] == 0 or desc2.shape[0] == 0:\n",
    "        return np.zeros((0, 3))\n",
    "    if nn_thresh < 0.0:\n",
    "        raise ValueError('\\'nn_thresh\\' should be non-negative')\n",
    "\n",
    "    # Compute L2 distance. Easy since vectors are unit normalized.\n",
    "    dmat = np.dot(desc1, desc2.T)\n",
    "    dmat = np.sqrt(2-2*np.clip(dmat, -1, 1))\n",
    "\n",
    "    # Get NN indices and scores.\n",
    "    idx = np.argmin(dmat, axis=1)\n",
    "    scores = dmat[np.arange(dmat.shape[0]), idx]\n",
    "    \n",
    "    # Threshold the NN matches.\n",
    "    keep = scores < nn_thresh\n",
    "   \n",
    "    # Check if nearest neighbor goes both directions and keep those.\n",
    "    idx2 = np.argmin(dmat, axis=0)\n",
    "    keep_bi = np.arange(len(idx)) == idx2[idx]\n",
    "    keep = np.logical_and(keep, keep_bi)\n",
    "    idx = idx[keep]\n",
    "    scores = scores[keep]\n",
    "   \n",
    "    # Get the surviving point indices.\n",
    "    m_idx1 = np.arange(desc1.shape[0])[keep]\n",
    "    m_idx2 = idx\n",
    "    \n",
    "    # Populate the final Nx3 match data structure.\n",
    "    matches = np.zeros((int(keep.sum()), 3))\n",
    "    matches[:, 0] = m_idx1\n",
    "    matches[:, 1] = m_idx2\n",
    "    matches[:, 2] = scores\n",
    "    return matches\n",
    "\n",
    "def compute_distances_kpts_to_epilines(points_i, points_j, F:np.array) -> np.array:\n",
    "    \"\"\"Given two sets of matching points [Nx2] returns the an array of absolute\n",
    "    distances [Nx2], where as the first column contains the distances of the \n",
    "    first points to the  epipolar lines in the first image and the second image\n",
    "    vise versa.\"\"\"\n",
    "    assert points_i.shape[1] == 2\n",
    "    assert points_j.shape[1] == 2\n",
    "    assert points_i.shape == points_j.shape\n",
    "    \n",
    "    if F is None:\n",
    "        return (np.zeros((points_i.shape[0], 2)) + np.inf)\n",
    "\n",
    "    # Epipolar lines in image I of the points in image J\n",
    "    lines_i = cv2.computeCorrespondEpilines(points_j.reshape(-1, 1, 2), 2, F).reshape(-1, 3)\n",
    "\n",
    "    # Epipolar lines in image J of the points in image I\n",
    "    lines_j = cv2.computeCorrespondEpilines(points_i.reshape(-1, 1, 2), 1, F).reshape(-1, 3)\n",
    "\n",
    "    dist = []\n",
    "    for k in range(points_i.shape[0]):\n",
    "        # Params for image i\n",
    "        xi, yi = points_i[k]\n",
    "        ai, bi, ci = lines_i[k]\n",
    "\n",
    "        # Params for image j\n",
    "        xj, yj = points_j[k]\n",
    "        aj, bj, cj = lines_j[k]\n",
    "\n",
    "        di = np.abs(ai*xi + bi*yi + ci) / np.sqrt(ai*ai + bi*bi)\n",
    "        dj = np.abs(aj*xj + bj*yj + cj) / np.sqrt(aj*aj + bj*bj)\n",
    "\n",
    "        dist.append((di, dj))\n",
    "\n",
    "    dist = np.array(dist)\n",
    "    return dist\n",
    "\n",
    "def save_stats(\n",
    "    path_output:str,\n",
    "    fout_name,\n",
    "    collection_name:str,\n",
    "    df:pd.DataFrame,\n",
    "    fast_eval:bool=False) -> None:\n",
    "    \n",
    "    if not os.path.exists(path_output):\n",
    "        os.makedirs(path_output, exist_ok=True)\n",
    "\n",
    "    df.to_csv(os.path.join(path_output, fout_name), \n",
    "              index=False, \n",
    "              encoding='utf-8')\n",
    "\n",
    "#####################\n",
    "### DATAFRAME\n",
    "#####################\n",
    "\"\"\"\n",
    "collection_name:str             Name of the collection\n",
    "set_name:str                    Name of the set\n",
    "kpts_threshold:int              Number of used features\n",
    "descriptor_name:str             Name of descriptor\n",
    "detector_name:str               Name of detector\n",
    "matching_method:str             Name of matching method\n",
    "desc_distance_threshold:float   Maximal distance of two descriptor to match for nn2w method\n",
    "ransac_threshold:int            Maximal distance in pixel between two points after estimation\n",
    "                                of F and projecting the one point to the other.\n",
    "ransac_confidence:float         Confidence level of the ransac algorithm when estimating\n",
    "                                the fundamental matrix. [0, 1].\n",
    "\n",
    "max_num_matches:int             Maximal number of possible matches\n",
    "num_matches:int                 Actual number of matches\n",
    "matchability:float              Ratio of num_matches and max_num_matches\n",
    "accuracy_matches:float          Mean of 1 - (score of match / desc_distance_threshold).\n",
    "                                Lies in range [0, 1].\n",
    "mse_matching:float              Mean squared error of matched desriptors.\n",
    "\n",
    "max_num_inliers:int             Maximal number of inliers for F-matrix\n",
    "num_inliers:int                 Actual number of inliers for F-matrix\n",
    "inlier_ratio:float              Ratio between num_inliers and max_num_inliers\n",
    "accuracy_inliers:               \n",
    "avg_distance:float              Mean distance between keypoints and corresponding epipolar line\n",
    "mse_estimation:float            Mean squared error\n",
    "\"\"\"\n",
    "\n",
    "column_names = ['collection_name', 'set_name', 'kpts_threshold',\n",
    "                'descriptor_name', 'detector_name', 'matching_method',\n",
    "                'desc_distance_threshold', 'ransac_threshold',\n",
    "                'ransac_confidence', 'max_num_matches',\n",
    "                'num_matches', 'matchability', 'accuracy_matches',\n",
    "                'mse_matching', 'max_num_inliers', 'num_inliers', \n",
    "                'inlier_ratio', 'avg_distance','mse_estimation']\n",
    "\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "#####################\n",
    "### SETTINGS\n",
    "#####################\n",
    "\n",
    "root_dir = '/home/mizzade/Workspace/diplom/code'\n",
    "image_dir = os.path.join(root_dir, 'data')\n",
    "data_dir = os.path.join(root_dir, 'outputs')\n",
    "output_dir = '/home/mizzade/Workspace/diplom/outputs/eval_matching_pipeline'\n",
    "\n",
    "iname1 = '1.png'\n",
    "iname2 = '2.png'\n",
    "fname1 = '1_10000.csv'\n",
    "fname2 = '2_10000.csv'\n",
    "file_scheme = '_10000.csv'\n",
    "\n",
    "collection_name = 'eisert'\n",
    "collection_path_data = os.path.join(data_dir, collection_name)\n",
    "collection_path_img = os.path.join(image_dir, collection_name)\n",
    "\n",
    "kpts_thresholds = [1000, 5000, 10000]\n",
    "desc_distance_thresholds = [0.7]\n",
    "   \n",
    "fout_name = 'descriptor_matching_{}_nn2w_fmatrix'.format(collection_name)\n",
    "\n",
    "ransac_threshold = 3\n",
    "ransac_confidence = .99\n",
    "\n",
    "#####################\n",
    "### MAIN\n",
    "#####################\n",
    "# NOTE: To avoid memory errors, handle number of descriptors, detecotrs,\n",
    "# keypoint threshold etc with car.\n",
    "\n",
    "\n",
    "set_names = sorted([x for x in os.listdir(collection_path_img) \\\n",
    "                    if os.path.isdir(os.path.join(collection_path_img, x))])\n",
    "\n",
    "fast_eval = False\n",
    "verbose = False\n",
    "\n",
    "fout_name = fout_name + '_fast.csv' if fast_eval else fout_name + '.csv'\n",
    "\n",
    "for set_name in tqdm(set_names):\n",
    "    if verbose:\n",
    "        print(set_name)\n",
    "    \n",
    "    # 1. Open folder of set\n",
    "    set_path_2_desc = os.path.join(collection_path_data, set_name, 'descriptors')\n",
    "    desc_names = sorted([x for x in os.listdir(set_path_2_desc) \\\n",
    "                               if os.path.isdir(os.path.join(set_path_2_desc, x))])\n",
    "\n",
    "    descriptor_names = desc_names[:2] if fast_eval else desc_names\n",
    "    for descriptor_name in descriptor_names:\n",
    "        if verbose:\n",
    "            print(descriptor_name)\n",
    "        \n",
    "        set_path_2_dets = os.path.join(set_path_2_desc, descriptor_name)\n",
    "        \n",
    "        det_names = sorted([x for x in os.listdir(set_path_2_dets) \\\n",
    "                                 if os.path.isdir(os.path.join(set_path_2_dets, x))])\n",
    "        \n",
    "        detector_names = det_names[:2] if fast_eval else det_names\n",
    "        for detector_name in detector_names:\n",
    "            if verbose:\n",
    "                print('\\t', detector_name)\n",
    "            \n",
    "            set_path_2_files = os.path.join(set_path_2_dets, detector_name)\n",
    "            file_names = sorted([x for x in os.listdir(set_path_2_files) if file_scheme in x])\n",
    "            \n",
    "            # 2. Open detector keypoints.\n",
    "            kpts_path = os.path.join(collection_path_data, set_name, 'keypoints', detector_name)\n",
    "            kpts1 = pd.read_csv(os.path.join(kpts_path, fname1), sep=',', comment='#', header=None, usecols=[0, 1]).values\n",
    "            kpts2 = pd.read_csv(os.path.join(kpts_path, fname2), sep=',', comment='#', header=None, usecols=[0, 1]).values\n",
    "\n",
    "            # 3. Open corresponding descriptors\n",
    "            desc_path = os.path.join(collection_path_data, set_name, 'descriptors', descriptor_name, detector_name)\n",
    "            desc1 = pd.read_csv(os.path.join(desc_path, fname1), sep=',', comment='#', header=None).values\n",
    "            desc2 = pd.read_csv(os.path.join(desc_path, fname2), sep=',', comment='#', header=None).values\n",
    "            desc1 = normalize_descriptors(desc1)\n",
    "            desc2 = normalize_descriptors(desc2)\n",
    "            \n",
    "            kpts_thresholds = kpts_thresholds[:1] if fast_eval else kpts_thresholds\n",
    "            for kpts_thresh in kpts_thresholds:\n",
    "                # 4. Get the subset of descriptors and detectors\n",
    "                # Make a copy, otherwise you overwrite the slices of \n",
    "                # the original.\n",
    "                d1 = desc1[:kpts_thresh].copy()\n",
    "                d2 = desc2[:kpts_thresh].copy()\n",
    "                k1 = kpts1[:kpts_thresh].copy()\n",
    "                k2 = kpts2[:kpts_thresh].copy()\n",
    "                \n",
    "                max_num_matches = np.min([len(d1), len(d2)])\n",
    "                \n",
    "                for desc_dist in desc_distance_thresholds:\n",
    "                    # 5. Make Nearest Neighbour Two Way Matching for each desc_dist\n",
    "                    # Column1 contains match indices of d1.\n",
    "                    # Column2 contains match indices of d2.\n",
    "                    # Column3 contains distance of descriptors.\n",
    "                    res = nn_match_two_way(d1, d2, desc_dist)\n",
    "                    \n",
    "                    num_matches = len(res)\n",
    "                    matchability = 0 \\\n",
    "                        if max_num_matches == 0 \\\n",
    "                        else num_matches / max_num_matches\n",
    "                    \n",
    "                    accuracy_matches = 0 \\\n",
    "                        if num_matches == 0 \\\n",
    "                        else 1.0 - np.mean(res[:, 2] / desc_dist)\n",
    "                    \n",
    "                    mse_matching = 0 \\\n",
    "                        if num_matches == 0 \\\n",
    "                        else np.mean(np.linalg.norm(res[:, 2]))\n",
    "                    \n",
    "                    max_num_inliers = len(res)\n",
    "                    \n",
    "                    # Indices of kpts1 and kpts2 matches\n",
    "                    idx1 = res[:, 0].astype(np.int)\n",
    "                    idx2 = res[:, 1].astype(np.int)\n",
    "                    \n",
    "                    # Get matching keypoints. Float32 for using cv2 functions.\n",
    "                    hits1 = (k1.copy()[idx1]).astype(np.float32)\n",
    "                    hits2 = (k2.copy()[idx2]).astype(np.float32)\n",
    "                    \n",
    "                    # ransacReprojThreshold: Maximal distance in pixels from point to epipolar line\n",
    "                    # to be condiered inlier.\n",
    "                    # confidence: Confidence value that fundamental matrix is correct.\n",
    "                    F, mask = cv2.findFundamentalMat(\n",
    "                        hits1, \n",
    "                        hits2, \n",
    "                        method=cv2.FM_RANSAC,\n",
    "                        ransacReprojThreshold=ransac_threshold,\n",
    "                        confidence=ransac_confidence)\n",
    "                    \n",
    "                    if  mask is not None:\n",
    "                        num_inliers = 0 if mask is None else np.sum(mask)\n",
    "                        inlier_ratio = 0 if len(res) == 0 else np.sum(mask) / len(res)\n",
    "                        \n",
    "                        mask = mask.ravel()\n",
    "                        hits1 = hits1[mask==1]\n",
    "                        hits2 = hits2[mask==1]\n",
    "\n",
    "                        # Absolute distances of points to corresponding epipoloar line\n",
    "                        # Column1: distances of points in image1 to epilines\n",
    "                        # Column2: distances of points in image2 to epilines\n",
    "                        #d_errors = compute_distances_kpts_to_epilines(hits1, hits2, F)\n",
    "                        d_errors = compute_distances_kpts_to_epilines(hits1, hits2, F)\n",
    "                        d_errors = d_errors.reshape(-1, 1)\n",
    "                        \n",
    "                        mean_dist = np.mean(d_errors)\n",
    "                        \n",
    "                        accuracy_inliers = 0 \\\n",
    "                            if num_inliers == 0 \\\n",
    "                            else 1.0 - mean_dist / ransac_threshold\n",
    "                        \n",
    "                        mse_estimation = 0 \\\n",
    "                            if len(d_errors) == 0 \\\n",
    "                            else np.linalg.norm(d_errors) / len(d_errors)\n",
    "\n",
    "                    else:\n",
    "                        num_inliers = 0\n",
    "                        inlier_ratio = 0\n",
    "                        mean_dist = np.nan\n",
    "                        mse_estimation = np.nan\n",
    "                        accuracy_inliers = 0\n",
    "                        \n",
    "                    # Add to dataframe\n",
    "                    df = df.append({\n",
    "                        'collection_name': collection_name, \n",
    "                        'set_name': set_name, \n",
    "                        'kpts_threshold': kpts_thresh,\n",
    "                        'descriptor_name': descriptor_name, \n",
    "                        'detector_name': detector_name, \n",
    "                        'matching_method': 'nn2w',\n",
    "                        'desc_distance_threshold': desc_dist,\n",
    "                        'ransac_threshold': ransac_threshold,\n",
    "                        'ransac_confidence': ransac_confidence,\n",
    "                        'max_num_matches': max_num_matches,\n",
    "                        'num_matches': num_matches,\n",
    "                        'matchability': matchability,\n",
    "                        'accuracy_matches': accuracy_matches,\n",
    "                        'mse_matching': mse_matching,\n",
    "                        'max_num_inliers': max_num_inliers,\n",
    "                        'num_inliers': num_inliers,\n",
    "                        'inlier_ratio': inlier_ratio,\n",
    "                        'accuracy_inliers': accuracy_inliers,\n",
    "                        'avg_distance': mean_dist,\n",
    "                        'mse_estimation': mse_estimation\n",
    "                    }, ignore_index=True)\n",
    "                    \n",
    "                    \n",
    "                    # Free memory\n",
    "                    del idx1, idx2, F, mask, num_inliers, inlier_ratio, mean_dist, mse_estimation, hits1, hits2\n",
    "                    del num_matches, matchability, accuracy_matches, mse_matching, accuracy_inliers\n",
    "                    gc.collect()\n",
    "                \n",
    "                # Free memory\n",
    "                del d1, d2, k1, k2, max_num_matches\n",
    "                gc.collect()\n",
    "            \n",
    "            # Free memory\n",
    "            del kpts1, kpts2, desc1, desc2\n",
    "            gc.collect()\n",
    "\n",
    "save_stats(\n",
    "    output_dir,\n",
    "    fout_name,\n",
    "    collection_name,\n",
    "    df,\n",
    "    fast_eval=fast_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
