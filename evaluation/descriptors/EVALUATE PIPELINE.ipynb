{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import collections\n",
    "import matplotlib as mpl\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get statistics for Fundamental Matrix Estimation using Mutal Nearest Neighbour Matching (NN2W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "### FUNCTIONS\n",
    "#####################\n",
    "\n",
    "def get_tcovdet_scale_factor(image:np.array) -> float:\n",
    "    \"\"\"Keypoints from tcovdet need to be scaled to fit\n",
    "    correctly onto the source image, since tcovdet internally\n",
    "    uses only an 1024x768 reprentation.\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    scale_factor = 1.0\n",
    "    \n",
    "    if (h * w) > 1024*768:\n",
    "        scale_factor = 1. / (1024 * 768 / float(h * w))**(0.5)\n",
    "        \n",
    "    return scale_factor\n",
    "\n",
    "def remove_duplicates_from_matches(matches:np.array) -> np.array:\n",
    "    \"\"\"Removes all matches where descriptors have been assigned multiple times.\"\"\"\n",
    "    \n",
    "    assert matches.shape[1] == 3\n",
    "    \n",
    "    # 1. Sort by distances\n",
    "    res = matches[matches[:, 2].argsort()]\n",
    "    \n",
    "    # 2. Get unique ids of first column\n",
    "    _, uid = np.unique(res[:, 0], return_index=True)\n",
    "    \n",
    "    # 3. Keep only the first unique entry, which is also the best (because of step 1).\n",
    "    res = res[uid]\n",
    "    \n",
    "    \n",
    "    # 4. Repeat 1-3 for second column.\n",
    "    res = matches[matches[:, 2].argsort()]\n",
    "    _, uid = np.unique(res[:, 1], return_index=True)\n",
    "    res = res[uid]\n",
    "    \n",
    "    return res\n",
    "\n",
    "def normalize_descriptors(desc:np.array) -> np.array:\n",
    "    \"\"\"Creates unit vectors for each descriptor.\"\"\"    \n",
    "    _n = np.linalg.norm(desc, axis=1, ord=2) # Get norms of each vector\n",
    "    _d = desc / _n.reshape(-1, 1)            # Build unit vector\n",
    "    \n",
    "    return _d\n",
    "\n",
    "def nn_match_two_way(desc1, desc2, nn_thresh):\n",
    "    \"\"\"\n",
    "    Performs two-way nearest neighbor matching of two sets of descriptors, such\n",
    "    that the NN match from descriptor A->B must equal the NN match from B->A.\n",
    "\n",
    "    Inputs:\n",
    "      desc1 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      desc2 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      nn_thresh - Optional descriptor distance below which is a good match.\n",
    "\n",
    "    Returns:\n",
    "      matches - Lx3 numpy array, of L matches, where L <= N and each column i is\n",
    "                a match of two descriptors, d_i in image 1 and d_j' in image 2:\n",
    "                [d_i index, d_j' index, match_score]\n",
    "    \"\"\"\n",
    "    # Check if descriptor dimensions match\n",
    "    assert desc1.shape[1] == desc2.shape[1]\n",
    "\n",
    "    # Return zero matches, if one image does not have a keypoint and\n",
    "    # therefore no descriptors.\n",
    "    if desc1.shape[0] == 0 or desc2.shape[0] == 0:\n",
    "        return np.zeros((0, 3))\n",
    "    if nn_thresh < 0.0:\n",
    "        raise ValueError('\\'nn_thresh\\' should be non-negative')\n",
    "\n",
    "    # Compute L2 distance. Easy since vectors are unit normalized.\n",
    "    dmat = np.dot(desc1, desc2.T)\n",
    "    dmat = np.sqrt(2-2*np.clip(dmat, -1, 1))\n",
    "\n",
    "    # Get NN indices and scores.\n",
    "    idx = np.argmin(dmat, axis=1)\n",
    "    scores = dmat[np.arange(dmat.shape[0]), idx]\n",
    "    \n",
    "    # Threshold the NN matches.\n",
    "    keep = scores < nn_thresh\n",
    "   \n",
    "    # Check if nearest neighbor goes both directions and keep those.\n",
    "    idx2 = np.argmin(dmat, axis=0)\n",
    "    keep_bi = np.arange(len(idx)) == idx2[idx]\n",
    "    keep = np.logical_and(keep, keep_bi)\n",
    "    idx = idx[keep]\n",
    "    scores = scores[keep]\n",
    "   \n",
    "    # Get the surviving point indices.\n",
    "    m_idx1 = np.arange(desc1.shape[0])[keep]\n",
    "    m_idx2 = idx\n",
    "    \n",
    "    # Populate the final Nx3 match data structure.\n",
    "    matches = np.zeros((int(keep.sum()), 3))\n",
    "    matches[:, 0] = m_idx1\n",
    "    matches[:, 1] = m_idx2\n",
    "    matches[:, 2] = scores\n",
    "    return matches\n",
    "\n",
    "def nn_match_bf_ratio(desc1:np.array, desc2:np.array, nn_thresh:float, k:int=2) -> np.array:\n",
    "    \"\"\"Descriptor matching using bruteforce L2-distance matching with ratio test\n",
    "    for the 2 top matches.\"\"\"\n",
    "    \n",
    "    d1 = desc1.astype(np.float32)\n",
    "    d2 = desc2.astype(np.float32)\n",
    "    \n",
    "    # Create matcher object on the fly.\n",
    "    matcher = cv2.BFMatcher() # using L2-Bruteforce\n",
    "    \n",
    "    # Find best k matches for each descriptor.\n",
    "    knn_matches = matcher.knnMatch(d1, d2, k)\n",
    "    \n",
    "    # Filter each matching pair (first, second) using the Lowe's ratio test\n",
    "    # desc_dist is here the ratio threshold (0.7)\n",
    "    # Create Nx3 array for the matches containing\n",
    "    # - the id of the descriptor in d1\n",
    "    # - the id of the descriptor in d2\n",
    "    # - the distance between those two\n",
    "    res = []\n",
    "    for first_match, second_match in knn_matches:\n",
    "        if first_match.distance < desc_dist * second_match.distance:\n",
    "            res.append((first_match.queryIdx, first_match.trainIdx, first_match.distance))\n",
    "\n",
    "    res = np.array(res).reshape(-1, 3)\n",
    "    \n",
    "    # Take absolute distances\n",
    "    res[:, 2] = np.abs(res[:, 2])\n",
    "    \n",
    "    # Keep only matches with distance < nn_thresh\n",
    "    res = res[res[:, 2] < nn_thresh]\n",
    "    \n",
    "    # Remove duplicate matches\n",
    "    res = remove_duplicates_from_matches(res)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def nn_match_bf(desc1:np.array, desc2:np.array, nn_thresh:float, k:int=1) -> np.array:\n",
    "    \"\"\"Descriptor matching using L2-distance brute force matching\"\"\"\n",
    "    \n",
    "    d1 = desc1.astype(np.float32)\n",
    "    d2 = desc2.astype(np.float32)\n",
    "    \n",
    "    # Create matcher object on the fly.\n",
    "    matcher = cv2.BFMatcher() # using L2-Bruteforce\n",
    "    \n",
    "    # Find best k matches for each descriptor.\n",
    "    knn_matches = matcher.knnMatch(d1, d2, k)\n",
    "    \n",
    "    # Filter each matching pair (first, second) using the Lowe's ratio test\n",
    "    # desc_dist is here the ratio threshold (0.7)\n",
    "    # Create Nx3 array for the matches containing\n",
    "    # - the id of the descriptor in d1\n",
    "    # - the id of the descriptor in d2\n",
    "    # - the distance between those two\n",
    "    res = []\n",
    "    for first_match, in knn_matches:\n",
    "        res.append((first_match.queryIdx, first_match.trainIdx, first_match.distance))\n",
    "\n",
    "    res = np.array(res).reshape(-1, 3)\n",
    "    \n",
    "    # Take absolute distances\n",
    "    res[:, 2] = np.abs(res[:, 2])\n",
    "    \n",
    "    # Keep only matches with distance < nn_thresh\n",
    "    res = res[res[:, 2] < nn_thresh]\n",
    "    \n",
    "    # Remove duplicate matches\n",
    "    res = remove_duplicates_from_matches(res)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def nn_match_flann(desc1:np.array, desc2:np.array, nn_thresh:float, k:int=1) -> np.array:\n",
    "    \"\"\"Descriptor matching using one sided L2-distance nearest neighbour matching.\"\"\"\n",
    "    \n",
    "    d1 = desc1.astype(np.float32)\n",
    "    d2 = desc2.astype(np.float32)\n",
    "    \n",
    "    # Create matcher object on the fly.\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "    \n",
    "    # Find best k matches for each descriptor.\n",
    "    knn_matches = matcher.knnMatch(d1, d2, k)\n",
    "    \n",
    "    # Filter each matching pair (first, second) using the Lowe's ratio test\n",
    "    # desc_dist is here the ratio threshold (0.7)\n",
    "    # Create Nx3 array for the matches containing\n",
    "    # - the id of the descriptor in d1\n",
    "    # - the id of the descriptor in d2\n",
    "    # - the distance between those two\n",
    "    res = []\n",
    "    for first_match, in knn_matches:\n",
    "        res.append((first_match.queryIdx, first_match.trainIdx, first_match.distance))\n",
    "\n",
    "    res = np.array(res).reshape(-1, 3)\n",
    "    \n",
    "    # Take absolute distances\n",
    "    res[:, 2] = np.abs(res[:, 2])\n",
    "    \n",
    "    # Keep only matches with distance < nn_thresh\n",
    "    res = res[res[:, 2] < nn_thresh]\n",
    "    \n",
    "    # Remove duplicate matches\n",
    "    res = remove_duplicates_from_matches(res)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def nn_match_flann_ratio(desc1:np.array, desc2:np.array, nn_thresh:float, k:int=2) -> np.array:\n",
    "    \"\"\"Descriptor matching using FLANN L2-distance matching with ratio test\n",
    "    for the 2 top matches.\"\"\"\n",
    "    \n",
    "    d1 = desc1.astype(np.float32)\n",
    "    d2 = desc2.astype(np.float32)\n",
    "    \n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "    \n",
    "    # Find best k matches for each descriptor.\n",
    "    \n",
    "    try:\n",
    "        knn_matches = matcher.knnMatch(d1, d2, k)\n",
    "    except:\n",
    "        return np.array([]).reshape(-1,3)\n",
    "    \n",
    "    # Filter each matching pair (first, second) using the Lowe's ratio test\n",
    "    # desc_dist is here the ratio threshold (0.7)\n",
    "    # Create Nx3 array for the matches containing\n",
    "    # - the id of the descriptor in d1\n",
    "    # - the id of the descriptor in d2\n",
    "    # - the distance between those two\n",
    "    res = []\n",
    "    for first_match, second_match in knn_matches:\n",
    "        if first_match.distance < desc_dist * second_match.distance:\n",
    "            res.append((first_match.queryIdx, first_match.trainIdx, first_match.distance))\n",
    "\n",
    "    res = np.array(res).reshape(-1, 3)\n",
    "    \n",
    "    # Take absolute distances\n",
    "    res[:, 2] = np.abs(res[:, 2])\n",
    "    \n",
    "    # Keep only matches with distance < nn_thresh\n",
    "    res = res[res[:, 2] < nn_thresh]\n",
    "    \n",
    "    # Remove duplicate matches\n",
    "    res = remove_duplicates_from_matches(res)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def compute_distances_kpts_to_epilines(points_i, points_j, F:np.array) -> np.array:\n",
    "    \"\"\"Given two sets of matching points [Nx2] returns the an array of absolute\n",
    "    distances [Nx2], where as the first column contains the distances of the \n",
    "    first points to the  epipolar lines in the first image and the second image\n",
    "    vise versa.\"\"\"\n",
    "    assert points_i.shape[1] == 2\n",
    "    assert points_j.shape[1] == 2\n",
    "    assert points_i.shape == points_j.shape\n",
    "    \n",
    "    if F is None:\n",
    "        return (np.zeros((points_i.shape[0], 2)) + np.inf)\n",
    "\n",
    "    # Epipolar lines in image I of the points in image J\n",
    "    lines_i = cv2.computeCorrespondEpilines(points_j.reshape(-1, 1, 2), 2, F).reshape(-1, 3)\n",
    "\n",
    "    # Epipolar lines in image J of the points in image I\n",
    "    lines_j = cv2.computeCorrespondEpilines(points_i.reshape(-1, 1, 2), 1, F).reshape(-1, 3)\n",
    "\n",
    "    dist = []\n",
    "    for k in range(points_i.shape[0]):\n",
    "        # Params for image i\n",
    "        xi, yi = points_i[k]\n",
    "        ai, bi, ci = lines_i[k]\n",
    "\n",
    "        # Params for image j\n",
    "        xj, yj = points_j[k]\n",
    "        aj, bj, cj = lines_j[k]\n",
    "\n",
    "        di = np.abs(ai*xi + bi*yi + ci) / np.sqrt(ai*ai + bi*bi)\n",
    "        dj = np.abs(aj*xj + bj*yj + cj) / np.sqrt(aj*aj + bj*bj)\n",
    "\n",
    "        dist.append((di, dj))\n",
    "\n",
    "    dist = np.array(dist)\n",
    "    return dist\n",
    "\n",
    "def save_stats(\n",
    "    path_output:str,\n",
    "    fout_name,\n",
    "    collection_name:str,\n",
    "    df:pd.DataFrame,\n",
    "    fast_eval:bool=False) -> None:\n",
    "    \n",
    "    if not os.path.exists(path_output):\n",
    "        os.makedirs(path_output, exist_ok=True)\n",
    "\n",
    "    df.to_csv(os.path.join(path_output, fout_name), \n",
    "              index=False, \n",
    "              encoding='utf-8')\n",
    "\n",
    "#####################\n",
    "### DATAFRAME\n",
    "#####################\n",
    "\"\"\"\n",
    "collection_name:str             Name of the collection\n",
    "set_name:str                    Name of the set\n",
    "kpts_threshold:int              Number of used features\n",
    "descriptor_name:str             Name of descriptor\n",
    "detector_name:str               Name of detector\n",
    "matching_method:str             Name of matching method\n",
    "desc_distance_threshold:float   Maximal distance of two descriptor to match for nn2w method\n",
    "ransac_threshold:int            Maximal distance in pixel between two points after estimation\n",
    "                                of F and projecting the one point to the other.\n",
    "ransac_confidence:float         Confidence level of the ransac algorithm when estimating\n",
    "                                the fundamental matrix. [0, 1].\n",
    "\n",
    "num_kpts_i:int                  Number of found keypoints in first image at kpts threshold level.\n",
    "num_kpts_j:int                  Number of found keypoints in second image at kpts threshold level.\n",
    "max_num_matches:int             Maximal number of possible matches\n",
    "num_matches:int                 Actual number of matches\n",
    "matchability:float              Ratio of num_matches and max_num_matches\n",
    "accuracy_matches:float          Mean of 1 - (score of match / desc_distance_threshold).\n",
    "                                Lies in range [0, 1].\n",
    "mse_matching:float              Mean squared error of matched desriptors.\n",
    "\n",
    "max_num_inliers:int             Maximal number of inliers for F-matrix\n",
    "num_inliers:int                 Actual number of inliers for F-matrix\n",
    "inlier_ratio:float              Ratio between num_inliers and max_num_inliers\n",
    "accuracy_inliers:               \n",
    "avg_distance:float              Mean distance between keypoints and corresponding epipolar line\n",
    "mse_estimation:float            Mean squared error\n",
    "\"\"\"\n",
    "\n",
    "column_names = ['collection_name', 'set_name', 'kpts_threshold',\n",
    "                'descriptor_name', 'detector_name', 'matching_method',\n",
    "                'desc_distance_threshold', 'ransac_threshold',\n",
    "                'ransac_confidence', 'num_kpts_i', 'num_kpts_j', 'max_num_matches',\n",
    "                'num_matches', 'matchability', 'accuracy_matches',\n",
    "                'mse_matching', 'max_num_inliers', 'num_inliers', \n",
    "                'inlier_ratio', 'avg_distance','mse_estimation']\n",
    "\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "#####################\n",
    "### SETTINGS\n",
    "#####################\n",
    "\n",
    "root_dir = '/home/mizzade/Workspace/diplom/code'\n",
    "image_dir = os.path.join(root_dir, 'data')\n",
    "data_dir = os.path.join(root_dir, 'outputs')\n",
    "output_dir = '/home/mizzade/Workspace/diplom/outputs/eval_matching_pipeline'\n",
    "\n",
    "iname1 = '1.png'\n",
    "iname2 = '2.png'\n",
    "fname1 = '1_10000.csv'\n",
    "fname2 = '2_10000.csv'\n",
    "file_scheme = '_10000.csv'\n",
    "\n",
    "collection_name = 'eisert'\n",
    "collection_path_data = os.path.join(data_dir, collection_name)\n",
    "collection_path_img = os.path.join(image_dir, collection_name)\n",
    "\n",
    "kpts_thresholds = [1000, 5000, 10000]\n",
    "desc_distance_thresholds = [0.7]\n",
    "   \n",
    "ransac_threshold = 3\n",
    "ransac_confidence = .99\n",
    "\n",
    "# Parameters depending on selected matching method.\n",
    "eval_dict = {\n",
    "    'nn2way': {\n",
    "        'matching_method': 'nn2way',\n",
    "        'file_name': 'descriptor_matching_eisert_nn2way',\n",
    "        'matching_function': nn_match_two_way},\n",
    "    'bf_ratio': {\n",
    "        'matching_method': 'bf_ratio',\n",
    "        'file_name': 'descriptor_matching_eisert_bf_ratio',\n",
    "        'matching_function': nn_match_bf_ratio},\n",
    "    'bf': {\n",
    "        'matching_method': 'bf',\n",
    "        'file_name': 'descriptor_matching_eisert_bf',\n",
    "        'matching_function': nn_match_bf},\n",
    "    'flann': {\n",
    "        'matching_method': 'flann',\n",
    "        'file_name': 'descriptor_matching_eisert_flann',\n",
    "        'matching_function': nn_match_flann},\n",
    "    'flann_ratio': {\n",
    "        'matching_method': 'flann_ratio',\n",
    "        'file_name': 'descriptor_matching_eisert_flann_ratio',\n",
    "        'matching_function': nn_match_flann_ratio}\n",
    "}\n",
    "#####################\n",
    "### MAIN\n",
    "#####################\n",
    "# NOTE: To avoid memory errors, handle number of descriptors, detecotrs,\n",
    "# keypoint threshold etc with car.\n",
    "\n",
    "fast_eval = False\n",
    "verbose = False\n",
    "save_output = True\n",
    "normalize_desc = True\n",
    "\n",
    "# 1. Select which evaluations to plot (Make sure, data exist in data_dir):\n",
    "# nn2way | bf| bf_ratio | flann | flann_ratio\n",
    "matching_methods = ['nn2way', 'bf', 'bf_ratio', 'flann', 'flann_ratio']\n",
    "\n",
    "for matching_method in matching_methods:\n",
    "    \n",
    "    # Set output name for data frame.\n",
    "    fout_name = eval_dict[matching_method]['file_name']\n",
    "    \n",
    "    if not normalize_desc:\n",
    "        fout_name += '_no_normalization'\n",
    "    fout_name = fout_name + '_fast.csv' if fast_eval else fout_name + '.csv'\n",
    "    \n",
    "    print('Starting matching method ', matching_method)\n",
    "    print('Normalize descriptors: ', normalize_desc)\n",
    "    print('fout: ', fout_name)\n",
    "    \n",
    "\n",
    "    set_names = sorted([x for x in os.listdir(collection_path_img) \\\n",
    "                        if os.path.isdir(os.path.join(collection_path_img, x))])\n",
    "\n",
    "    for set_name in tqdm(set_names):\n",
    "        if verbose:\n",
    "            print(set_name)\n",
    "\n",
    "        # 0. Open image\n",
    "        imgs_path = os.path.join(image_dir, collection_name, set_name)\n",
    "        img_names = sorted([x for x in os.listdir(imgs_path) if os.path.isfile(os.path.join(imgs_path, x))])\n",
    "        img1 = mpimg.imread(os.path.join(imgs_path, img_names[0]))\n",
    "\n",
    "        tcovdet_scalefactor = get_tcovdet_scale_factor(img1)\n",
    "\n",
    "        # 1. Open folder of set\n",
    "        set_path_2_desc = os.path.join(collection_path_data, set_name, 'descriptors')\n",
    "        desc_names = sorted([x for x in os.listdir(set_path_2_desc) \\\n",
    "                                   if os.path.isdir(os.path.join(set_path_2_desc, x))])\n",
    "\n",
    "        descriptor_names = desc_names[:2] if fast_eval else desc_names\n",
    "        for descriptor_name in descriptor_names:\n",
    "            if verbose:\n",
    "                print(descriptor_name)\n",
    "\n",
    "            set_path_2_dets = os.path.join(set_path_2_desc, descriptor_name)\n",
    "\n",
    "            det_names = sorted([x for x in os.listdir(set_path_2_dets) \\\n",
    "                                     if os.path.isdir(os.path.join(set_path_2_dets, x))])\n",
    "\n",
    "            detector_names = det_names[:2] if fast_eval else det_names\n",
    "            for detector_name in detector_names:\n",
    "                if verbose:\n",
    "                    print('\\t', detector_name)\n",
    "\n",
    "                set_path_2_files = os.path.join(set_path_2_dets, detector_name)\n",
    "                file_names = sorted([x for x in os.listdir(set_path_2_files) if file_scheme in x])\n",
    "\n",
    "                # 2. Open detector keypoints.\n",
    "                kpts_path = os.path.join(collection_path_data, set_name, 'keypoints', detector_name)\n",
    "                kpts1 = pd.read_csv(os.path.join(kpts_path, fname1), \n",
    "                                    sep=',', comment='#', header=None, usecols=[0, 1]).values\n",
    "                kpts2 = pd.read_csv(os.path.join(kpts_path, fname2), \n",
    "                                    sep=',', comment='#', header=None, usecols=[0, 1]).values\n",
    "\n",
    "                # 2.1 If detector is tcovdet, we have to scale keypoints.\n",
    "                if detector_name == 'tcovdet':\n",
    "                    kpts1 = kpts1 * tcovdet_scalefactor\n",
    "                    kpts2 = kpts2 * tcovdet_scalefactor\n",
    "\n",
    "                # 3. Open corresponding descriptors\n",
    "                desc_path = os.path.join(collection_path_data, set_name, 'descriptors',\n",
    "                                         descriptor_name, detector_name)\n",
    "                desc1 = pd.read_csv(os.path.join(desc_path, fname1), sep=',', comment='#', header=None).values\n",
    "                desc2 = pd.read_csv(os.path.join(desc_path, fname2), sep=',', comment='#', header=None).values\n",
    "                \n",
    "                if normalize_desc:\n",
    "                    desc1 = normalize_descriptors(desc1)\n",
    "                    desc2 = normalize_descriptors(desc2)\n",
    "\n",
    "                kpts_thresholds = kpts_thresholds[:1] if fast_eval else kpts_thresholds\n",
    "                for kpts_thresh in kpts_thresholds:\n",
    "                    # 4. Get the subset of descriptors and detectors\n",
    "                    # Make a copy, otherwise you overwrite the slices of \n",
    "                    # the original.\n",
    "                    d1 = desc1[:kpts_thresh].copy()\n",
    "                    d2 = desc2[:kpts_thresh].copy()\n",
    "                    k1 = kpts1[:kpts_thresh].copy()\n",
    "                    k2 = kpts2[:kpts_thresh].copy()\n",
    "\n",
    "                    num_kpts_i = len(d1)\n",
    "                    num_kpts_j = len(d2)\n",
    "                    max_num_matches = np.min([num_kpts_i, num_kpts_j])\n",
    "\n",
    "\n",
    "                    for desc_dist in desc_distance_thresholds:\n",
    "                        # 5. Make Nearest Neighbour Two Way Matching for each desc_dist\n",
    "                        # Column1 contains match indices of d1.\n",
    "                        # Column2 contains match indices of d2.\n",
    "                        # Column3 contains distance of descriptors.\n",
    "                        res = eval_dict[matching_method]['matching_function'](d1, d2, desc_dist)\n",
    "\n",
    "                        num_matches = len(res)\n",
    "                        matchability = 0 \\\n",
    "                            if max_num_matches == 0 \\\n",
    "                            else num_matches / max_num_matches\n",
    "\n",
    "                        accuracy_matches = 0 \\\n",
    "                            if num_matches == 0 \\\n",
    "                            else np.clip(1.0 - np.mean(res[:, 2] / desc_dist), 0., 1.)\n",
    "\n",
    "                        mse_matching = 0 \\\n",
    "                            if num_matches == 0 \\\n",
    "                            else np.mean(np.linalg.norm(res[:, 2]))\n",
    "\n",
    "                        max_num_inliers = len(res)\n",
    "\n",
    "                        # Indices of kpts1 and kpts2 matches\n",
    "                        idx1 = res[:, 0].astype(np.int)\n",
    "                        idx2 = res[:, 1].astype(np.int)\n",
    "\n",
    "                        # Get matching keypoints. Float32 for using cv2 functions.\n",
    "                        hits1 = (k1.copy()[idx1]).astype(np.float32)\n",
    "                        hits2 = (k2.copy()[idx2]).astype(np.float32)\n",
    "\n",
    "                        # ransacReprojThreshold: Maximal distance in pixels from point to epipolar line\n",
    "                        # to be condiered inlier.\n",
    "                        # confidence: Confidence value that fundamental matrix is correct.\n",
    "\n",
    "                        # Need at least 7 points to creat Fundamental matrix.\n",
    "                        if num_matches >= 8: \n",
    "                            F, mask = cv2.findFundamentalMat(\n",
    "                                hits1, \n",
    "                                hits2, \n",
    "                                method=cv2.FM_RANSAC,\n",
    "                                ransacReprojThreshold=ransac_threshold,\n",
    "                                confidence=ransac_confidence)\n",
    "                        else:\n",
    "                            F, mask = None, None\n",
    "\n",
    "                        if  mask is not None and F is not None:\n",
    "                            num_inliers = 0 if mask is None else np.sum(mask)\n",
    "                            inlier_ratio = 0 if len(res) == 0 else np.sum(mask) / len(res)\n",
    "\n",
    "                            mask = mask.ravel()\n",
    "                            hits1 = hits1[mask==1]\n",
    "                            hits2 = hits2[mask==1]\n",
    "\n",
    "                            # Absolute distances of points to corresponding epipoloar line\n",
    "                            # Column1: distances of points in image1 to epilines\n",
    "                            # Column2: distances of points in image2 to epilines\n",
    "                            #d_errors = compute_distances_kpts_to_epilines(hits1, hits2, F)\n",
    "                            d_errors = compute_distances_kpts_to_epilines(hits1, hits2, F)\n",
    "                            d_errors = d_errors.reshape(-1, 1)\n",
    "\n",
    "                            mean_dist = np.mean(d_errors)\n",
    "\n",
    "                            accuracy_inliers = 0 \\\n",
    "                                if num_inliers == 0 \\\n",
    "                                else np.clip(1.0 - mean_dist / ransac_threshold, 0., 1.)\n",
    "\n",
    "                            mse_estimation = 0 \\\n",
    "                                if len(d_errors) == 0 \\\n",
    "                                else np.linalg.norm(d_errors) / len(d_errors)\n",
    "\n",
    "                        else:\n",
    "                            num_inliers = 0\n",
    "                            inlier_ratio = 0\n",
    "                            mean_dist = np.nan\n",
    "                            mse_estimation = np.nan\n",
    "                            accuracy_inliers = 0\n",
    "\n",
    "                        # Add to dataframe\n",
    "                        df = df.append({\n",
    "                            'collection_name': collection_name, \n",
    "                            'set_name': set_name, \n",
    "                            'kpts_threshold': kpts_thresh,\n",
    "                            'descriptor_name': descriptor_name, \n",
    "                            'detector_name': detector_name, \n",
    "                            'matching_method': matching_method,\n",
    "                            'desc_distance_threshold': desc_dist,\n",
    "                            'ransac_threshold': ransac_threshold,\n",
    "                            'ransac_confidence': ransac_confidence,\n",
    "                            'num_kpts_i': num_kpts_i,\n",
    "                            'num_kpts_j': num_kpts_j,\n",
    "                            'max_num_matches': max_num_matches,\n",
    "                            'num_matches': num_matches,\n",
    "                            'matchability': matchability,\n",
    "                            'accuracy_matches': accuracy_matches,\n",
    "                            'mse_matching': mse_matching,\n",
    "                            'max_num_inliers': max_num_inliers,\n",
    "                            'num_inliers': num_inliers,\n",
    "                            'inlier_ratio': inlier_ratio,\n",
    "                            'accuracy_inliers': accuracy_inliers,\n",
    "                            'avg_distance': mean_dist,\n",
    "                            'mse_estimation': mse_estimation\n",
    "                        }, ignore_index=True)\n",
    "\n",
    "\n",
    "                        # Free memory\n",
    "                        del idx1, idx2, F, mask, num_inliers, inlier_ratio, mean_dist, mse_estimation, hits1, hits2\n",
    "                        del num_matches, matchability, accuracy_matches, mse_matching, accuracy_inliers\n",
    "                        gc.collect()\n",
    "\n",
    "                    # Free memory\n",
    "                    del d1, d2, k1, k2, max_num_matches\n",
    "                    gc.collect()\n",
    "\n",
    "                # Free memory\n",
    "                del kpts1, kpts2, desc1, desc2, num_kpts_i, num_kpts_j\n",
    "                gc.collect()\n",
    "        \n",
    "        # Free memory\n",
    "        del img1\n",
    "        gc.collect()\n",
    "\n",
    "    if save_output:\n",
    "        save_stats(\n",
    "            output_dir,\n",
    "            fout_name,\n",
    "            collection_name,\n",
    "            df,\n",
    "            fast_eval=fast_eval)\n",
    "\n",
    "    print(matching_method, ' done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
