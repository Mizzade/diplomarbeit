{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Detector Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nn_match_two_way(kpts1, kpts2, dist):\n",
    "    \"\"\"\n",
    "    Performs two-way nearest neighbor matching of two sets of keypoints, such\n",
    "    that the match from keypoints A->B must equal the match from B->A.\n",
    "\n",
    "    Inputs:\n",
    "      kpts1 - NxM numpy matrix of N corresponding M-dimensional keypoints.\n",
    "      kpts2 - NxM numpy matrix of N corresponding M-dimensional keypoints.\n",
    "      dist - Distance in pixels below that two keypoints are considered a match.\n",
    "\n",
    "    Returns:\n",
    "      matches - Lx4 numpy array, of L matches, where L <= N and each column i is\n",
    "                a match of two keypoints, d_i in image 1 and d_j' in image 2:\n",
    "                [d_i index, d_j' index, l2 distance, accurcy]\n",
    "    \"\"\"\n",
    "    # Check if descriptor dimensions match\n",
    "    assert kpts1.shape[1] == kpts2.shape[1]\n",
    "\n",
    "    # Return zero matches, if one image does not have a keypoint and\n",
    "    # therefore no descriptors.\n",
    "    if kpts1.shape[0] == 0 or kpts2.shape[0] == 0:\n",
    "        return np.zeros((0, 4))\n",
    "    if dist <= 0.0:\n",
    "        raise ValueError('\\'nn_thresh\\' should greater zero')\n",
    "\n",
    "    # Compute L2 distance. Easy since vectors are unit normalized.\n",
    "    dmat = np.linalg.norm(kpts2-kpts1[:, np.newaxis], axis=2)\n",
    "\n",
    "    # Get NN indices and scores.\n",
    "    idx = np.argmin(dmat, axis=1)\n",
    "    scores = dmat[np.arange(dmat.shape[0]), idx]\n",
    "    \n",
    "    # Threshold the NN matches.\n",
    "    keep = scores < dist\n",
    "   \n",
    "    # Check if nearest neighbor goes both directions and keep those.\n",
    "    idx2 = np.argmin(dmat, axis=0)\n",
    "    keep_bi = np.arange(len(idx)) == idx2[idx]\n",
    "    keep = np.logical_and(keep, keep_bi)\n",
    "    idx = idx[keep]\n",
    "    scores = scores[keep]\n",
    "   \n",
    "    # Get the surviving point indices.\n",
    "    m_idx1 = np.arange(kpts1.shape[0])[keep]\n",
    "    m_idx2 = idx\n",
    "    \n",
    "    # Populate the final Nx3 match data structure.\n",
    "    matches = np.zeros((int(keep.sum()), 4))\n",
    "    matches[:, 0] = m_idx1\n",
    "    matches[:, 1] = m_idx2\n",
    "    matches[:, 2] = scores\n",
    "    matches[:, 3] = 1.0 - (scores / dist)\n",
    "    return matches\n",
    "\n",
    "def stats_for_imagepair(kpts1:np.array, kpts2:np.array, t:int, kp_thresh:int) -> Tuple[int, int, float, np.array]:\n",
    "    matches = nn_match_two_way(kpts1, kpts2, t)\n",
    "    \n",
    "    max_num_matches = np.min([kpts1.shape[0], kpts2.shape[0]])\n",
    "    num_matches = len(matches)\n",
    "    \n",
    "    repeatability = 0 if max_num_matches == 0 else num_matches / max_num_matches\n",
    "    accuracy = np.mean(matches[:, 3])\n",
    "    \n",
    "    return max_num_matches, num_matches, repeatability, accuracy\n",
    "\n",
    "def get_set_names(data_dir:str, sort_output:bool=True) -> List[str]:\n",
    "    set_names = [x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x))]\n",
    "\n",
    "    if sort_output:\n",
    "        set_names = sorted(set_names)\n",
    "    \n",
    "    return set_names\n",
    "\n",
    "def get_file_names_in_set(path_set:str, file_scheme:str, sort_output:bool=True) -> List[str]:\n",
    "    file_names = [x for x in os.listdir(path_set) if os.path.isfile(os.path.join(path_set, x))]\n",
    " \n",
    "    # get the correct files with fitting file scheme.\n",
    "    file_names = [x for x in file_names if file_scheme in x]\n",
    "\n",
    "    if sort_output:\n",
    "        file_names = sorted(file_names)\n",
    "\n",
    "    return file_names\n",
    "\n",
    "def evaluate_detector(\n",
    "    df:pd.DataFrame,\n",
    "    detector_name:str,\n",
    "    collection_name:str,\n",
    "    path_collection:str,\n",
    "    set_names:List[str],\n",
    "    file_scheme:str,\n",
    "    keypoint_thresholds:List[int],\n",
    "    dist_error_thresholds:List[float],\n",
    "    fast_eval:bool=False) -> pd.DataFrame:\n",
    "\n",
    "    for set_name in set_names:\n",
    "        path_set = os.path.join(path_collection, set_name, 'keypoints', detector_name)\n",
    "        file_names = get_file_names_in_set(path_set, file_scheme)\n",
    "        num_files = 5 if fast_eval else len(file_names)\n",
    "        for i in tqdm(range(num_files)):\n",
    "            path_f1 = os.path.join(path_set, file_names[i])\n",
    "            f1 = pd.read_csv(path_f1, \n",
    "                             sep=',', \n",
    "                             header=None, \n",
    "                             usecols=[0, 1], \n",
    "                             comment='#').values.astype('float32')\n",
    "            num_kpts_i = f1.shape[0]\n",
    "\n",
    "            for j in range(i+1,num_files,1):\n",
    "                path_f2 = os.path.join(path_set, file_names[j])\n",
    "                f2 = pd.read_csv(path_f2, \n",
    "                                 sep=',', \n",
    "                                 header=None, \n",
    "                                 usecols=[0, 1], \n",
    "                                 comment='#').values.astype('float32')\n",
    "                num_kpts_j = f2.shape[0]\n",
    "\n",
    "\n",
    "                for kp_thresh in keypoint_thresholds:\n",
    "                    _f1 = f1[:kp_thresh]\n",
    "                    _f2 = f2[:kp_thresh]\n",
    "                    \n",
    "                    for dist_threshold in dist_error_thresholds:\n",
    "                        max_num_matches, num_matches, repeatability, accuracy = \\\n",
    "                            stats_for_imagepair(_f1, _f2, dist_threshold, kp_thresh)\n",
    "                        \n",
    "                        # lambda term. Note: lambdad is reserved word in python.\n",
    "                        lambdaa = max_num_matches / kp_thresh\n",
    "                        \n",
    "                        # Append new row to dataframe.\n",
    "                        df = df.append({\n",
    "                            'collection_name': collection_name,\n",
    "                            'set_name': set_name,\n",
    "                            'detector_name': detector_name,\n",
    "                            'image_i': file_names[i],\n",
    "                            'image_j': file_names[j],\n",
    "                            'num_kpts_i': num_kpts_i,\n",
    "                            'num_kpts_j': num_kpts_j,\n",
    "                            'keypoint_threshold': kp_thresh,\n",
    "                            'dist_threshold': dist_threshold,\n",
    "                            'max_num_matches': max_num_matches,\n",
    "                            'num_matches': num_matches,\n",
    "                            'repeatability': repeatability,\n",
    "                            'accuracy': accuracy,\n",
    "                            'lambda': lambdaa\n",
    "                            }, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def save(\n",
    "    path_output:str,\n",
    "    collection_name:str,\n",
    "    df:pd.DataFrame,\n",
    "    fast_eval:bool=False) -> None:\n",
    "\n",
    "    if fast_eval:\n",
    "        fout_name = 'repeatability_{}_fast.csv'.format(collection_name)\n",
    "    else:\n",
    "        fout_name = 'repeatability_{}.csv'.format(collection_name)\n",
    "    \n",
    "    if not os.path.exists(path_output):\n",
    "        os.makedirs(path_output, exist_ok=True)\n",
    "\n",
    "    df.to_csv(os.path.join(path_output, fout_name), \n",
    "              index=False, \n",
    "              encoding='utf-8')\n",
    "\n",
    "\n",
    "#################################\n",
    "### DATAFRAME\n",
    "#################################\n",
    "# 'collection_name':str           Name of the collection.\n",
    "# 'set_name':str                  Name of the set.         \n",
    "# 'detector_name':str             Name of the detector.\n",
    "# 'image_i':str                   Name of the first (left) image.\n",
    "# 'image_j':str                   Name of the second (right) image.\n",
    "# 'num_kpts_i':int                Number of keypoints found in first \n",
    "#                                 image.\n",
    "# 'num_kpts_j':int                Number of keypoints found in the \n",
    "#                                 second image.\n",
    "# 'keypoint_threshold':int        Number of keypoints to use. \n",
    "#                                 [1000, 5000, 10000].\n",
    "# 'dist_percentage':float         Maximal match distance in percentage \n",
    "#                                 to count \n",
    "#                                 as match.Relative to image dimensions. \n",
    "#                                 [1, 5, 10]\n",
    "# 'max_num_matches':int           Maximal number of possible matches  \n",
    "#                                 under current conditions.\n",
    "# 'num_matches':int               Actual number of matches.\n",
    "# 'repeatability':float           Ratio of number of matched keypoints \n",
    "#                                 to max_num_matches.\n",
    "# 'accuracy':float                Mean accuracy for all matches.\n",
    "# 'lambda':float                  Ratio of max_num_matches to keypoint_threshold.\n",
    "#                                 [0, 1]\n",
    "column_names = ['collection_name','set_name', 'detector_name', \n",
    "                'image_i', 'image_j', 'num_kpts_i', 'num_kpts_j', \n",
    "                'keypoint_threshold', 'dist_threshold', \n",
    "                'max_num_matches', 'num_matches', \n",
    "                'repeatability', 'accuracy', 'lambda']\n",
    "\n",
    "#################################\n",
    "### PARAMS\n",
    "#################################\n",
    "# Adjust this accordingly\n",
    "\n",
    "# root_dir = '/Users/mirkolauff/Workbench/diplom/notebooks'\n",
    "data_dir = '/home/mizzade/Workspace/diplom/outputs'\n",
    "output_dir = os.path.join(data_dir, 'eval_detectors')\n",
    "\n",
    "collection_name = 'webcam'\n",
    "path_collection = os.path.join(data_dir, collection_name)\n",
    "\n",
    "file_scheme = '_10000.csv'\n",
    "detector_names = ['sift', 'lift', 'tcovdet' , 'tilde', 'superpoint']\n",
    "\n",
    "set_names = get_set_names(path_collection, sort_output=True)\n",
    "keypoint_thresholds = [1000, 5000, 10000]\n",
    "dist_error_thresholds = [3] # in pixels\n",
    "\n",
    "#################################\n",
    "### MAIN\n",
    "#################################\n",
    "\n",
    "fast_eval = False\n",
    "\n",
    "# Create output dataframe.\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# Skip superpoint when fast eval\n",
    "detector_names = detector_names[:4] if fast_eval else detector_names\n",
    "\n",
    "for detector_name in detector_names:\n",
    "    print('Start evaluation of detector {}.'.format(detector_name))\n",
    "    df = evaluate_detector(\n",
    "     df,\n",
    "     detector_name,\n",
    "     collection_name,\n",
    "     path_collection,\n",
    "     set_names,\n",
    "     file_scheme,\n",
    "     keypoint_thresholds,\n",
    "     dist_error_thresholds,\n",
    "     fast_eval=fast_eval)\n",
    "    \n",
    "    print('Evaluation of detector {} complete.'.format(detector_name))\n",
    "    \n",
    "save(\n",
    "    output_dir, \n",
    "    collection_name, \n",
    "    df,\n",
    "    fast_eval=fast_eval)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
